
# üìù Publications 

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">arXiv Preprint</div><img src='images/arxiv.PNG' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[An Adaptive and Momental Bound Method for Stochastic Learning](https://arxiv.org/abs/1910.12249) \\
**Jianbang Ding**, Xuancheng Ren, Ruixuan Luo, Xu Sun \\
[[Paper]](https://arxiv.org/abs/1910.12249) [[Code]](https://github.com/lancopku/AdaMod) [[Video]](https://www.youtube.com/watch?v=vx8thj3XZfw) \\
\\
We propose [**AdaMod** ![](https://img.shields.io/github/stars/lancopku/adamod?style=social)](https://github.com/lancopku/AdaMod), an improvement over the Adam optimizer by adding in a long-term memory aspect. \\
\\
Just **pip install adamod** to try it! Up to now, it has multiple several variants and implementations, supporting both [Pytorch](https://github.com/lessw2020/Best-Deep-Learning-Optimizers), [Tensorflow](https://github.com/evanatyourservice/AdaMod-tf), [Keras](https://github.com/superkido511/AdaMod-Keras).
</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">NLPCC 2023</div><img src='images/nlpcc.jpg' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[An Adaptive Learning Method for Solving the Extreme Learning Rate Problem of Transformer](https://link.springer.com/chapter/10.1007/978-3-031-44693-1_29) \\
**Jianbang Ding**, Xuancheng Ren, Ruixuan Luo \\
[[Paper]](https://link.springer.com/chapter/10.1007/978-3-031-44693-1_29) [[Code]](https://github.com/lancopku/AdaMod) [[Video]](https://www.youtube.com/watch?v=vx8thj3XZfw) \\
\\
Conducting more empirical studies on AdaMod. \\
\\
**Some third-party's Comments**:
  - "*In testing AdaMod on some datasets along with other optimizers, I find that AdaMod is consistently a top 5 optimizer.*" ‚Äî‚Äî[Less Wright](https://lessw.medium.com/meet-adamod-a-new-deep-learning-optimizer-with-memory-f01e831b80bd)
  - "*I‚Äôve had great success with this wrapped in lookahead.*" ‚Äî‚Äî[Evan Walters](https://medium.com/@EvanLWalters)
</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">CCL 2023</div><img src='images/ccl.JPG' alt="sym" width="100%" height="100px"></div></div>
<div class='paper-box-text' markdown="1">

[Adder Encoder for Pre-trained Language Model](https://aclanthology.org/2023.ccl-1.76.pdf) \\
**Jianbang Ding**, Suiyun Zhang \\
[[Paper]](https://aclanthology.org/2023.ccl-1.76.pdf) [[Poster]](https://github.com/karrynest/karrynest.github.io/blob/main/images/poster.jpg) \\
\\
üéâ**CCL Best Poster Award** \\
Empirical results demonstrate that AddderBERT achieves highly competitive performance against that of BERT-base on the GLUE benchmark while obtaining a **4.9x** reduction in energy consumption.
</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">IJCNN 2024</div><img src='images/ijcnn.JPG' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Disfluency Detection for Real-World Scenarios](https://ieeexplore.ieee.org/document/10650005) \\
**Jianbang Ding**, Suiyun Zhang, Dandan Tu \\
[[Paper]](https://ieeexplore.ieee.org/document/10650005) [[Slide]]() [[Video]]() \\

**Oral Paper** \\
Experimental results show that our approach significantly outperforms previous baselines and achieves state-of-the-art performance (94.3 F-score) on English Switchboard corpus.
</div>
</div>
